{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "x_train = train[0]/255.\n",
    "x_train = x_train[..., None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/c7021101/anaconda3/envs/master/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "latent = 49\n",
    "img_size = (28, 28, 1)\n",
    "classes = 10\n",
    "\n",
    "\n",
    "def conv_layer(inp, filters, kernel_size=(3, 3), dropout=0, transpose=False, **kwargs):\n",
    "    out = tf.keras.layers.Conv2D(filters, kernel_size=kernel_size, padding='same', **kwargs)(inp)\n",
    "    if transpose:\n",
    "        out = tf.keras.layers.Conv2DTranspose(filters, kernel_size=kernel_size, padding='valid', **kwargs)(inp)\n",
    "    if dropout:\n",
    "        out = tf.keras.layers.Dropout(rate=dropout)(out)\n",
    "    out = tf.keras.layers.PReLU(shared_axes=[1, 2])(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Define discriminator\n",
    "def get_discriminator(img_dim=(28, 28, 1), class_dim=10, filters=32):\n",
    "    x_input = tf.keras.layers.Input(img_dim)\n",
    "\n",
    "    d = conv_layer(x_input, filters=filters)\n",
    "    d = conv_layer(d, filters=filters)\n",
    "    d = conv_layer(d, filters=filters, strides=(2, 2))\n",
    "    d = conv_layer(d, filters=filters, strides=(2, 2))\n",
    "    d = tf.keras.layers.Flatten()(d)\n",
    "    d = tf.keras.layers.Dense(class_dim, activation='relu')(d)\n",
    "\n",
    "    y_input = tf.keras.layers.Input(img_dim)\n",
    "    dy = conv_layer(y_input, filters=filters)\n",
    "    dy = conv_layer(dy, filters=filters)\n",
    "    dy = conv_layer(dy, filters=filters, strides=(2, 2))\n",
    "    dy = conv_layer(dy, filters=filters, strides=(2, 2))\n",
    "    dy = tf.keras.layers.Flatten()(dy)\n",
    "    dy = tf.keras.layers.Dense(class_dim, activation='relu')(dy)\n",
    "\n",
    "    out = tf.keras.layers.Concatenate()([d, dy])\n",
    "    out = tf.keras.layers.Dense(256, activation='relu')(out)\n",
    "    out = tf.keras.layers.Dense(1, activation='relu')(out)\n",
    "    \n",
    "    r = conv_layer(x_input, filters=filters, strides=(4, 4))\n",
    "    r = tf.keras.layers.Flatten()(r)\n",
    "    r = tf.keras.layers.Dense(1, activation='relu')(r)\n",
    "    \n",
    "    out = tf.keras.layers.Add()([out, r])\n",
    "    \n",
    "\n",
    "    discriminator = tf.keras.Model(inputs=[x_input, y_input], outputs=out)\n",
    "    return discriminator\n",
    "\n",
    "disc = get_discriminator()\n",
    "dvars = disc.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_descent(tf.keras.layers.Layer):\n",
    "    def __init__(self, discriminator, iterations=10, eta=1e-3, sigma=0.1):\n",
    "        super(gradient_descent, self).__init__()\n",
    "        self.iterations = iterations\n",
    "        self.eta = eta\n",
    "        self.discriminator = discriminator\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build gradients here for hopefully faster execution\n",
    "        self.discriminator.trainable = False\n",
    "        pass\n",
    "\n",
    "\n",
    "    def call(self, input):\n",
    "        out = input[0]\n",
    "        y = input[1]\n",
    "        #tik = self.discriminator([out, y])\n",
    "        err = [self.discriminator([out, y])]\n",
    "        for iteration in range(self.iterations):\n",
    "            grads = tf.gradients(self.discriminator([out, y]), out)[0]\n",
    "            out = out - self.eta*(grads + self.sigma*out)\n",
    "            err.append(self.discriminator([out, y]))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(discriminator, K=10, img_dim=(28, 28, 1), filters=32):\n",
    "    y_input = tf.keras.layers.Input(img_dim)\n",
    "    d = conv_layer(y_input, filters=filters)\n",
    "    d = conv_layer(d, filters=filters)\n",
    "    d = conv_layer(d, filters=filters)\n",
    "    d = conv_layer(d, filters=filters)\n",
    "    x0 = conv_layer(d, filters=1)\n",
    "    \n",
    "    # Gradient descent\n",
    "    eta = 1e-1\n",
    "    out = gradient_descent(discriminator, eta=eta)([x0, y_input])\n",
    "        \n",
    "    generator = tf.keras.Model(inputs=y_input, outputs=[out, x0])\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = get_generator(disc)\n",
    "gvars = gen.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/c7021101/anaconda3/envs/master/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Discriminator tries to map x_true to output 1 and generator_out to output 0\n",
    "# Generator tries to find images such that discriminator thinks they are output 1\n",
    "LAM = 1e2\n",
    "lr = 1e-3\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, ) + img_size)\n",
    "y = tf.placeholder(tf.float32, (None, ) + img_size)\n",
    "\n",
    "line = tf.placeholder(tf.float32, (None, 1, 1, 1))\n",
    "\n",
    "x_gen = gen(y)[0]\n",
    "x_init = gen(y)[1]\n",
    "x_line = x*line + x_gen*(1-line)\n",
    "\n",
    "\n",
    "lip = LAM*sum([(tf.reduce_mean(g**2)-1)**2 for g in tf.gradients(disc([x_line, y]), [x_line, y])])\n",
    "\n",
    "loss_disc = tf.reduce_mean(-disc([x_gen, y]) + disc([x, y]) + lip)\n",
    "loss_gen = tf.reduce_mean(disc([x_gen, y]))\n",
    "\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "\n",
    "grads_gen, _ = tf.clip_by_global_norm(tf.gradients(loss_gen, gvars), 1.)\n",
    "grads_disc, _ = tf.clip_by_global_norm(tf.gradients(loss_disc, dvars), 1.)\n",
    "\n",
    "train_gen = opt.apply_gradients(zip(grads_gen, gvars))\n",
    "train_disc = opt.apply_gradients(zip(grads_disc, dvars))\n",
    "\n",
    "############\n",
    "# Active gradients\n",
    "\n",
    "total_gen = int(np.sum([np.prod(t.shape) for t in gvars]))\n",
    "active_gen = sum([tf.count_nonzero(grad) for grad in grads_gen if grad is not None])/total_gen\n",
    "\n",
    "total_disc = int(np.sum([np.prod(t.shape) for t in dvars]))\n",
    "active_disc = sum([tf.count_nonzero(grad) for grad in grads_disc if grad is not None])/total_disc\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size=8):\n",
    "    x = x_train[np.random.choice(60000, batch_size), ...]\n",
    "    y = x + np.random.normal(0, 0.2, x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Epoch 0 ###\n",
      "Progress: 0.064000, Disc: 192.202316, Gen: 42.127823\r"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "N = 2000\n",
    "batch_size = 32\n",
    "ncritic = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    LOSSD = []\n",
    "    LOSSG = []\n",
    "    print(\"### Epoch %d ###\" % epoch)\n",
    "\n",
    "    for batch in range(N // batch_size):\n",
    "        CRITIC = []\n",
    "        for i in range(ncritic):\n",
    "            xinp, yinp = generate_batch(batch_size=batch_size)\n",
    "            t = np.random.uniform(0, 1, (batch_size, 1, 1, 1))\n",
    "            fd = {x: xinp,\n",
    "                 y: yinp,\n",
    "                 line: t}\n",
    "            ld, _ = sess.run([loss_disc, train_disc], feed_dict=fd)\n",
    "            CRITIC.append(ld)\n",
    "            \n",
    "        _, yinp = generate_batch(batch_size=batch_size)\n",
    "        lg, _ = sess.run([loss_gen, train_gen], feed_dict={y: yinp})\n",
    "\n",
    "        LOSSG.append(lg)\n",
    "        LOSSD.append(np.mean(CRITIC))\n",
    "        print(\"Progress: %f, Disc: %f, Gen: %f\" % (batch*batch_size/N, np.mean(LOSSD), np.mean(LOSSG)), end='\\r')\n",
    "    \n",
    "    xinp, yinp = generate_batch(batch_size=1)\n",
    "    gx = sess.run([x_init, x_gen], feed_dict={y: yinp})\n",
    "    dx = sess.run(disc([x, y]), feed_dict={y: np.concatenate([yinp, yinp]), x: np.concatenate(gx)})\n",
    "    print(dx.flatten())\n",
    "    plt.subplot(151)\n",
    "    plt.imshow(xinp[0, ..., 0])\n",
    "    plt.title(\"True\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(152)\n",
    "    plt.imshow(yinp[0, ..., 0])\n",
    "    plt.title(\"Data\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(153)\n",
    "    plt.imshow(gx[0][0, ..., 0])\n",
    "    plt.title(\"Initial\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(154)\n",
    "    plt.imshow(gx[1][0, ..., 0])\n",
    "    plt.title(\"Predicted\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.subplot(155)\n",
    "    plt.imshow(gx[1][0, ..., 0] - gx[0][0, ..., 0])\n",
    "    plt.title(\"Diff\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
